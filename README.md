# Hari-Priya-Kandasamy

Hello! I am Hari Priya Kandasamy, a Software Engineer specializing in Large Language Models (LLMs), search, information retrieval, and Retrieval-Augmented Generation (RAG). I am currently located in Sunnyvale, CA, where I'm building a generative LLM-powered assistant for conversational data discovery and designed scalable lineage tracing systems. Previously, I conducted machine learning research at the AI Health Lab, University of Texas at Austin, developing ViT-based models for clinical datasets and predictive patient outcome forecasting. I have a background in Data Science and hold a Master's in Information Science from The University of Texas at Austin. My passion lies in developing scalable AI-driven solutions that enhance information access and retrieval.

Outside of work, I enjoy playing softball, reading and exploring new hobbies

Recent Work:

01. Multimodal RAG for Technical Documentation
A powerful retrieval-augmented generation (RAG) system designed to process and answer questions about technical documentation, including text, images, diagrams, and code snippets.
Python • LangChain • ChromaDB • FastAPI • React

02. Stock Advisor Agent
A stock advisor agent powered by AI provides users (with no prior stocks knowledge) with personalised stock investment recommendations based on risk portfolio,news analysis and a dedicated chatbot to answer user queries.
Python • Transformers • Flask

03. Yottasecure Chatbot
Developing a LLM based chatbot, integrating Zero Trust security and SPIFFE/SPIRE APIs, to automate secure
identity management and user support within a healthcare context and enhancing chatbot intelligence by curating a specialized dataset, leading to a nuanced understanding of security-related queries and a user-friendly conversational experience.
Python • Rasa • Docker • Cybersecurity 

Master’s Thesis: A Comparative Study of Deep Learning Models with XAI for Chest X-ray Images (Computer vision, Deep Learning)
• Evaluated and compared deep learning models (Inceptionv4, Vision Transformer) against traditional CNNs for chest X-ray image
classification, leveraging NIH-CXR-LT and MIMIC-CXR-LT datasets, achieving breakthrough accuracy levels in medical imaging analysis.
• Demonstrated Vision Transformer's superiority over traditional CNNs, recording an impressive AUC of 0.9932; employed explainable AI
tools like GradCAM, SHAP to enhance model interpretability, significantly boosting clinical diagnostic precision.

Interested in collaborating?
Let’s connect if you're working on search infrastructure, semantic ranking, Gen AI search, or hiring engineers who love solving search problems with clean code, creative thinking, and real-world impact. Reach out to me at hpkanda@gmail.com

Leadership Roles
• International Graduate Student Agency Director, Graduate Student Assembly at UT Austin (June 2022- May 2023)
• Operations Manager, Make a Difference,Coimbatore (June 2019- June 2020)
